{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698276fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59a41d",
   "metadata": {},
   "source": [
    "### Read in Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2a0182",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('household_power_consumption.txt', sep=';', na_values='?', index_col=0,\n",
    "                       parse_dates=[[0,1]], infer_datetime_format=True, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e7843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 has 25979 bad values.\n",
      "Column 1 has 25979 bad values.\n",
      "Column 2 has 25979 bad values.\n",
      "Column 3 has 25979 bad values.\n",
      "Column 4 has 25979 bad values.\n",
      "Column 5 has 25979 bad values.\n",
      "Column 6 has 25979 bad values.\n"
     ]
    }
   ],
   "source": [
    "for i in range(raw_data.shape[1]):\n",
    "    bad_cnt = raw_data.iloc[:, i].isnull().sum()\n",
    "    print('Column %d has %d bad values.' % (i, bad_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8dcd36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2075259, 7)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "# print(raw_data.iloc[4,[2,3,6,7,8]])\n",
    "# print(raw_data.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8d9fb",
   "metadata": {},
   "source": [
    "### Fill missing data with average curve\n",
    "This method of filling the data will replace each missing value with the average of the last good value and the next good value. If there are multiple missing values, the last good value will be updated as each value is filled in. For example, if the series of data is [0, ?, ?, 4], the filled in set will be [0, 2, 3, 4].  \n",
    "I think this is a reasonable way to fill in power data since power is continuous and can't change value instantaneously. It might be problematic for the regions where there are many values (multiple days worth) missing, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768f2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Column 0 cleaned\n"
     ]
    }
   ],
   "source": [
    "filled_data = raw_data.copy()\n",
    "\n",
    "for col in range(1):#filled_data.shape[1]):\n",
    "    last_row = -2\n",
    "    \n",
    "    null_series = filled_data.iloc[:, col].isnull()\n",
    "    null_indices = np.where(null_series.values == True)[0].tolist()\n",
    "    print(type(null_indices))\n",
    "    skip_cnt = 0\n",
    "    for i in range(len(null_indices)):\n",
    "        row = null_indices[i]\n",
    "        \n",
    "        if (last_row == row - 1):\n",
    "            new_val = (last_good + next_good) / 2\n",
    "            filled_data.iloc[row] = new_val\n",
    "            last_good = new_val\n",
    "            continue\n",
    "            \n",
    "        if (i == len(null_indices) - 1):\n",
    "            # This is the last null value in the column. The next row is good.\n",
    "            filled_data.iloc[row] = (filled_data.iloc[row - 1] + filled_data.iloc[row + 1]) / 2\n",
    "        else:\n",
    "            good_idx = 0\n",
    "            for k in range(i, len(null_indices)):\n",
    "                if (null_indices[k] != null_indices[k + 1] - 1):\n",
    "                    good_idx = k\n",
    "                    break\n",
    "                elif (k == len(null_indices) - 1):\n",
    "                    good_idx = k\n",
    "            next_good = filled_data.iloc[null_indices[good_idx] + 1]\n",
    "            last_good = filled_data.iloc[row - 1]\n",
    "            new_val = (last_good + next_good) / 2\n",
    "            filled_data.iloc[row] = new_val\n",
    "            last_good = new_val\n",
    "            last_row = row\n",
    "                \n",
    "    print('Column %d cleaned' % col)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4a90eb5",
   "metadata": {},
   "source": [
    "# Check a few missing value locations to verify the fill worked correctly\n",
    "print(raw_data.iloc[6838])\n",
    "print(filled_data.iloc[6839])\n",
    "print(filled_data.iloc[6840])\n",
    "print(raw_data.iloc[6841])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e21c8",
   "metadata": {},
   "source": [
    "### Add a new column for apparent power\n",
    "If I remember my power systems courses correctly, the power utility needs to consider apparent power, which is a combination of both active and reactive power. This next bit of code will calculate the apparent power and add it as a new column. This column will be useful if we want to do analysis related to how much power the utility needs to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f22007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add apparent power column\n",
    "filled_data['Global_apparent_power'] = np.sqrt(filled_data['Global_active_power']**2 +\n",
    "                                              filled_data['Global_reactive_power']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ac242",
   "metadata": {},
   "source": [
    "### Aggregate data by hour/day/month/season rather than by minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6b0beb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Global_active_power  Global_reactive_power     Voltage  \\\n",
      "Date_Time                                                            \n",
      "2006-10-01             1.901571               0.131397  241.440774   \n",
      "2007-01-01             1.422664               0.120580  240.650054   \n",
      "2007-04-01             0.883693               0.125577  237.651833   \n",
      "2007-07-01             0.799100               0.122131  238.333030   \n",
      "2007-10-01             1.342161               0.100342  240.772614   \n",
      "2008-01-01             1.298108               0.092189  240.863683   \n",
      "2008-04-01             1.044563               0.143538  240.190038   \n",
      "2008-07-01             0.683049               0.133273  240.109304   \n",
      "2008-10-01             1.265784               0.099657  241.338747   \n",
      "2009-01-01             1.296449               0.099723  242.847055   \n",
      "2009-04-01             1.031554               0.128080  240.858863   \n",
      "2009-07-01             0.751356               0.169731  241.484303   \n",
      "2009-10-01             1.261095               0.129326  242.311544   \n",
      "2010-01-01             1.321115               0.121701  242.624206   \n",
      "2010-04-01             1.031445               0.132274  240.991049   \n",
      "2010-07-01             0.811980               0.138687  240.850327   \n",
      "2010-10-01             1.178627               0.125385  241.505340   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
      "Date_Time                                                                      \n",
      "2006-10-01          8.031117        27534.75       48761.250    1.629858e+05   \n",
      "2007-01-01          6.014953       164786.00      248685.500    8.902795e+05   \n",
      "2007-04-01          3.833693       177488.00      180529.500    6.084858e+05   \n",
      "2007-07-01          3.472192       132144.00      180932.250    6.070170e+05   \n",
      "2007-10-01          5.649873       168132.50      244546.000    9.182085e+05   \n",
      "2008-01-01          5.474578       165100.00      198836.000    8.478485e+05   \n",
      "2008-04-01          4.460052       168892.00      193230.250    8.764035e+05   \n",
      "2008-07-01          2.966504       103562.00      111270.000    5.911920e+05   \n",
      "2008-10-01          5.319799       147268.50      158655.750    8.661693e+05   \n",
      "2009-01-01          5.412525       186441.50      172086.500    9.545545e+05   \n",
      "2009-04-01          4.378020       129438.00      132505.875    9.614620e+05   \n",
      "2009-07-01          3.264338       103851.00      126889.000    6.766158e+05   \n",
      "2009-10-01          5.270907       172975.00      160694.000    1.046998e+06   \n",
      "2010-01-01          5.499772       138247.50      173060.500    1.132052e+06   \n",
      "2010-04-01          4.371333       152051.50      136535.000    1.007668e+06   \n",
      "2010-07-01          3.484645        67068.00      108300.000    7.124375e+05   \n",
      "2010-10-01          4.965795        94361.00      102524.000    5.627825e+05   \n",
      "\n",
      "            Global_apparent_power  \n",
      "Date_Time                          \n",
      "2006-10-01               1.914312  \n",
      "2007-01-01               1.436422  \n",
      "2007-04-01               0.904888  \n",
      "2007-07-01               0.822701  \n",
      "2007-10-01               1.352207  \n",
      "2008-01-01               1.307258  \n",
      "2008-04-01               1.066288  \n",
      "2008-07-01               0.712347  \n",
      "2008-10-01               1.275130  \n",
      "2009-01-01               1.305802  \n",
      "2009-04-01               1.049058  \n",
      "2009-07-01               0.787169  \n",
      "2009-10-01               1.276237  \n",
      "2010-01-01               1.334148  \n",
      "2010-04-01               1.049489  \n",
      "2010-07-01               0.836396  \n",
      "2010-10-01               1.193398  \n"
     ]
    }
   ],
   "source": [
    "hourly_data = filled_data.resample('H').agg({'Global_active_power': np.mean, 'Global_reactive_power': np.mean, 'Voltage': np.mean,\n",
    "                                'Global_intensity': np.mean, 'Sub_metering_1': np.sum, 'Sub_metering_2': np.sum,\n",
    "                                'Sub_metering_3': np.sum, 'Global_apparent_power': np.mean})\n",
    "\n",
    "daily_data = filled_data.resample('D').agg({'Global_active_power': np.mean, 'Global_reactive_power': np.mean, 'Voltage': np.mean,\n",
    "                                'Global_intensity': np.mean, 'Sub_metering_1': np.sum, 'Sub_metering_2': np.sum,\n",
    "                                'Sub_metering_3': np.sum, 'Global_apparent_power': np.mean})\n",
    "\n",
    "monthly_data = filled_data.resample('MS').agg({'Global_active_power': np.mean, 'Global_reactive_power': np.mean, 'Voltage': np.mean,\n",
    "                                'Global_intensity': np.mean, 'Sub_metering_1': np.sum, 'Sub_metering_2': np.sum,\n",
    "                                'Sub_metering_3': np.sum, 'Global_apparent_power': np.mean})\n",
    "\n",
    "season_data = filled_data.resample('QS-JUL').agg({'Global_active_power': np.mean, 'Global_reactive_power': np.mean, 'Voltage': np.mean,\n",
    "                                'Global_intensity': np.mean, 'Sub_metering_1': np.sum, 'Sub_metering_2': np.sum,\n",
    "                                'Sub_metering_3': np.sum, 'Global_apparent_power': np.mean})\n",
    "\n",
    "# print(season_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
